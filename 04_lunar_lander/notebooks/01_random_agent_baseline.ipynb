{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f0f5d97",
   "metadata": {},
   "source": [
    "# 01 Random agent baseline\n",
    "\n",
    "#### ðŸ‘‰Before you try to solve a Reinforcement Learning problem you should get a grasp of its difficulty.\n",
    "\n",
    "#### ðŸ‘‰ To do so, you need to design a dummy agent that can peform the task without much brains, and evaluate its performance.\n",
    "\n",
    "#### ðŸ‘‰A simple way to do so is by using a Random Agent, that chooses its next action randomly, without paying attention at the current state of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d9aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee0675",
   "metadata": {},
   "source": [
    "## Environment ðŸŒŽ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d2a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make('LunarLander-v3', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65c277c",
   "metadata": {},
   "source": [
    "## Random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361df1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "\n",
    "    def act(self, state) -> int:\n",
    "        \"\"\"\n",
    "        No input arguments to this function.\n",
    "        The agent does not consider the state of the environment when deciding\n",
    "        what to do next.\n",
    "        \"\"\"\n",
    "        return self.env.action_space.sample()\n",
    "\n",
    "agent = RandomAgent(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a19d004",
   "metadata": {},
   "source": [
    "## Evaluate performance of a Random agent â±ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bbd187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_episodes = 100\n",
    "reward_per_episode = []\n",
    "success_per_episode = []\n",
    "\n",
    "for i in tqdm(range(0, n_episodes)):\n",
    "\n",
    "    state, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    reward = None\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "        \n",
    "    reward_per_episode.append(total_reward)\n",
    "    success_per_episode.append(1 if reward > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad47153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "reward_avg = np.array(reward_per_episode).mean()\n",
    "reward_std = np.array(reward_per_episode).std()\n",
    "print(f'Reward average {reward_avg:.2f}, std {reward_std:.2f}')\n",
    "\n",
    "success_rate = np.array(success_per_episode).mean()\n",
    "print(f'Succes rate = {success_rate:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22155325",
   "metadata": {},
   "source": [
    "## Reward distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ab4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 4))\n",
    "ax.set_title(\"Rewards\")    \n",
    "pd.Series(reward_per_episode).plot(kind='hist', bins=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1899524",
   "metadata": {},
   "source": [
    "## Let's see our agent in action ðŸŽ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22fbee9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Workaround for pygame error: \"error: No available video device\"\n",
    "# See https://stackoverflow.com/questions/15933493/pygame-error-no-available-video-device?rq=1\n",
    "# This is probably needed only for Linux\n",
    "import os\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "from src.viz import show_video\n",
    "\n",
    "env = gym.make('LunarLander-v3', render_mode='rgb_array')\n",
    "show_video(agent, env, sleep_sec=0.01, seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b05ff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-GwqnSlDl-py3.12",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
