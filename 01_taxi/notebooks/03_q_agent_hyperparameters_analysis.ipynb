{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3aa4564",
   "metadata": {},
   "source": [
    "# 03 Q-agent hyperparameters analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7280d4fc",
   "metadata": {},
   "source": [
    "#### 👉RL agents are extremely sensitive to hyper-parameters.\n",
    "\n",
    "#### 👉In the previous notebook you trusted me when I set them, but in reality you will need to tune them yourself.\n",
    "\n",
    "#### 👉Let's play with them in a systematic way to gain a better intuition of how they impact learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ba4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb90d58",
   "metadata": {},
   "source": [
    "## Environment 🌎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb6f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"Taxi-v3\", render_mode=\"ansi\", max_episode_steps=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c1596",
   "metadata": {},
   "source": [
    "## Q-agent 🤖🧠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the current working directory is in the python path.\n",
    "# This is so that the notebook can find the `src` module.\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "\n",
    "# No need to copy paste the same QAgent\n",
    "# definition in every notebook, don't you think?\n",
    "from src.q_agent import QAgent\n",
    "\n",
    "# hyper-parameters\n",
    "# RL problems are full of these hyper-parameters.\n",
    "# For the moment, trust me when I set these values.\n",
    "# We will later play with these and see how they impact learning.\n",
    "alphas = [0.01, 0.1, 1]\n",
    "gammas = [0.1, 0.6, 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926e30da",
   "metadata": {},
   "source": [
    "## Training loop 🎡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f9061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.loops import train\n",
    "\n",
    "# exploration vs exploitation prob\n",
    "# let's start with a constant probability of 10%.\n",
    "epsilon = 0.1\n",
    "n_episodes = 1000\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for alpha in alphas:\n",
    "    for gamma in gammas:\n",
    "        \n",
    "        print(f'alpha: {alpha}, gamma: {gamma}')\n",
    "        agent = QAgent(env, alpha, gamma)\n",
    "        \n",
    "        _, timesteps, penalties = train(agent,\n",
    "                                        env,\n",
    "                                        n_episodes,\n",
    "                                        epsilon)\n",
    "        \n",
    "        # collect timesteps and penalties for this pair\n",
    "        # of hyper-parameters (alpha, gamma)\n",
    "        results_ = pd.DataFrame()\n",
    "        results_['timesteps'] = timesteps\n",
    "        results_['penalties'] = penalties\n",
    "        results_['alpha'] = alpha\n",
    "        results_['gamma'] = gamma\n",
    "        results = pd.concat([results, results_])\n",
    "\n",
    "# index -> episode\n",
    "results = results.reset_index().rename(\n",
    "    columns={'index': 'episode'})\n",
    "\n",
    "# add column with the 2 hyper-parameters\n",
    "results['hyperparameters'] = [\n",
    "    f'alpha={a}, gamma={g}'\n",
    "    for (a, g) in zip(results['alpha'], results['gamma'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f24934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.gcf()\n",
    "sns.lineplot(results, x='episode', y='timesteps',\n",
    "            hue='hyperparameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5dbff0",
   "metadata": {},
   "source": [
    "## That looks cool! 😎 But a bit too noisy... 😵‍💫\n",
    "## What about averaging over several runs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c9e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loops import train_many_runs\n",
    "\n",
    "alphas = [0.1, 1]\n",
    "gammas = [0.1, 0.6, 0.9]\n",
    "\n",
    "epsilon = 0.1\n",
    "n_episodes = 1000\n",
    "n_runs = 10\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for alpha in alphas:\n",
    "    for gamma in gammas:\n",
    "        \n",
    "        print(f'alpha: {alpha}, gamma: {gamma}')\n",
    "        agent = QAgent(env, alpha, gamma)\n",
    "        \n",
    "        timesteps, penalties = train_many_runs(agent,\n",
    "                                               env,\n",
    "                                               n_episodes,\n",
    "                                               epsilon,\n",
    "                                               n_runs)\n",
    "        \n",
    "        # collect timesteps and penalties for this pair of\n",
    "        # hyper-parameters (alpha, gamma)\n",
    "        results_ = pd.DataFrame()\n",
    "        results_['timesteps'] = timesteps\n",
    "        results_['penalties'] = penalties\n",
    "        results_['alpha'] = alpha\n",
    "        results_['gamma'] = gamma\n",
    "        results = pd.concat([results, results_])\n",
    "\n",
    "# index -> episode\n",
    "results = results.reset_index().rename(\n",
    "    columns={'index': 'episode'})\n",
    "\n",
    "results['hyperparameters'] = [\n",
    "    f'alpha={a}, gamma={g}'\n",
    "    for (a, g) in zip(results['alpha'], results['gamma'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa170dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 8)\n",
    "sns.lineplot(results, x='episode', y='timesteps', hue='hyperparameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f32157",
   "metadata": {},
   "source": [
    "## Nice one!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3fa1c",
   "metadata": {},
   "source": [
    "## What about `epsilon`? Is the current value of 10% the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyper-parameters so far\n",
    "alpha = 1.0\n",
    "gamma = 0.9\n",
    "\n",
    "epsilons = [0.01, 0.10, 0.9]\n",
    "n_runs = 10\n",
    "n_episodes = 200\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for epsilon in epsilons:\n",
    "        \n",
    "    print(f'epsilon: {epsilon}')\n",
    "    agent = QAgent(env, alpha, gamma)\n",
    "\n",
    "    timesteps, penalties = train_many_runs(agent,\n",
    "                                           env,\n",
    "                                           n_episodes,\n",
    "                                           epsilon,\n",
    "                                           n_runs)\n",
    "\n",
    "    # collect timesteps and penalties for this pair of\n",
    "    # hyper-parameters (alpha, gamma)\n",
    "    results_ = pd.DataFrame()\n",
    "    results_['timesteps'] = timesteps\n",
    "    results_['penalties'] = penalties\n",
    "    results_['epsilon'] = epsilon\n",
    "    results = pd.concat([results, results_])\n",
    "\n",
    "# index -> episode\n",
    "results = results.reset_index().rename(columns={'index': 'episode'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f993e6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 8)\n",
    "sns.lineplot(results, x='episode', y='timesteps', hue='epsilon')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 8)\n",
    "sns.lineplot(results, x='episode', y='penalties', hue='epsilon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e654a0ea",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
