{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb067213",
   "metadata": {},
   "source": [
    "# 07 Deep Q agent with good hyper-parameters\n",
    "\n",
    "#### üëâ Let's use a neural network model to approximate the Q function.\n",
    "\n",
    "#### üëâNeural networks are usually highly-parametric models that are able to fit complex patterns between the input features and the target.\n",
    "\n",
    "#### üëâ The type of neural network we will use is a Multi Layer Perceptron (MLP).\n",
    "\n",
    "#### üëâMLPs are stacks of linear models, interleaved with so called activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf8b27e",
   "metadata": {},
   "source": [
    "![nn](https://github.com/Paulescu/hands-on-rl/blob/main/03_cart_pole/images/neural_net.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a324a",
   "metadata": {},
   "source": [
    "## Environment üåé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a241f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e250b",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e192c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good hyper-parameters\n",
    "# make you feel great!\n",
    "hparams = {\n",
    "    'learning_rate': 0.00016151809562265122,\n",
    "    'discount_factor': 0.99,\n",
    "    'batch_size': 32,\n",
    "    'memory_size': 10000,\n",
    "    'freq_steps_train': 8,\n",
    "    'freq_steps_update_target': 10,\n",
    "    'n_steps_warm_up_memory': 1000,\n",
    "    'n_gradient_steps': 16,\n",
    "    'nn_hidden_layers': [256, 256],\n",
    "    'max_grad_norm': 10,\n",
    "    'normalize_state': False,\n",
    "    'epsilon_start': 0.9,\n",
    "    'epsilon_end': 0.14856584122699473,\n",
    "    'steps_epsilon_decay': 10000,\n",
    "}\n",
    "\n",
    "# Lapadula: New hparams from saved_agents/CartPole-v1/298/hparams.json\n",
    "hparams = {\"learning_rate\": 0.00045095481485457226, \"discount_factor\": 0.99, \"batch_size\": 16, \"memory_size\": 100000, \"freq_steps_update_target\": 10, \"n_steps_warm_up_memory\": 1000, \"freq_steps_train\": 8, \"n_gradient_steps\": 16, \"nn_hidden_layers\": [256, 256], \"max_grad_norm\": 1, \"normalize_state\": False, \"epsilon_start\": 0.9, \"epsilon_end\": 0.06286625175600052, \"steps_epsilon_decay\": 10000}\n",
    "\n",
    "SEED = 2386916045"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84cbcb9",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Fix random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50099f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import set_seed\n",
    "set_seed(env, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b279ecd",
   "metadata": {},
   "source": [
    "## Deep Q-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ddd427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.q_agent import QAgent\n",
    "agent = QAgent(env, **hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9432d2d6",
   "metadata": {},
   "source": [
    "## Train the agent üèãÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0bb125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loops import train\n",
    "train(agent, env, n_episodes=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f506a",
   "metadata": {},
   "source": [
    "## Evaluate the agent ‚è±Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loops import evaluate\n",
    "rewards, steps = evaluate(\n",
    "    agent, env,\n",
    "    n_episodes=1000,\n",
    "    epsilon=0.00\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3331fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "reward_avg = np.array(rewards).mean()\n",
    "reward_std = np.array(rewards).std()\n",
    "print(f'Reward average {reward_avg:.2f}, std {reward_std:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba2d5ad",
   "metadata": {},
   "source": [
    "## Let's see how far we got in each attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e64f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 4))\n",
    "ax.set_title(\"Rewards\")    \n",
    "pd.Series(rewards).plot(kind='hist', bins=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c054e82a",
   "metadata": {},
   "source": [
    "## Let's see our agent in action üé¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31915e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround for pygame error: \"error: No available video device\"\n",
    "# See https://stackoverflow.com/questions/15933493/pygame-error-no-available-video-device?rq=1\n",
    "# This is probably needed only for Linux\n",
    "import os\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "\n",
    "from src.viz import show_video\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "show_video(agent, env, sleep_sec=0.01, seed=123)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-8fWkZ9tT-py3.12",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
